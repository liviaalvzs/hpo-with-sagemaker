# Hyperparameter Optimization (HPO) - XGBoost e SageMaker üîçüöÄ

Artigo no Medium: [Explorando o Potencial do Amazon SageMaker na Otimiza√ß√£o de Par√¢metros para um Modelo¬†XGBoost](https://medium.com/@alvzslivia/explorando-o-potencial-do-amazon-sagemaker-na-otimiza%C3%A7%C3%A3o-de-par%C3%A2metros-para-um-modelo-xgboost-b8ed136efee7).

Este projeto explora o potencial do Amazon SageMaker na otimiza√ß√£o de par√¢metros para um modelo XGBoost. O objetivo principal √© maximizar o desempenho do modelo ajustando os hiperpar√¢metros de forma automatizada. 

Inicialmente, gera-se um conjunto de dados sint√©ticos que simulam caracter√≠sticas imobili√°rias.Em seguida, normaliza-se os dados e os divide-se em conjuntos de treinamento, teste e valida√ß√£o. Essa etapa √© importante pois permite avaliar o desempenho do modelo de forma precisa.

Utiliza-se o Amazon SageMaker para configurar e treinar um modelo XGBoost. 

Para otimizar os hiperpar√¢metros do modelo XGBoost, emprega-se o SageMaker Hyperparameter Tuner. Este componente automatiza o processo de busca pelos melhores hiperpar√¢metros, permitindo que o modelo alcance seu m√°ximo potencial de desempenho (dentro dos intervalos inseridos).
